{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27f0889-521d-4cec-b324-c10c46226b32",
   "metadata": {},
   "source": [
    "Correliations of the features with standartisation, scalling, transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e1005-c7dc-4420-84ce-c5d6241dd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "# feature log transformations \n",
    "\n",
    "df_copy['age'] = df_copy['age'].apply(lambda x: np.log(x+10)*3)\n",
    "df_copy['avg_glucose_level'] = df_copy['avg_glucose_level'].apply(lambda x: np.log(x+10)*2)\n",
    "df_copy['bmi'] = df_copy['bmi'].apply(lambda x: np.log(x+10)*2)\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing - label enconding and numerical value scaling\n",
    "ohe = OneHotEncoder()\n",
    "ss = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "\n",
    "## label encoding of ordinal categorical features\n",
    "for col in df_copy.columns:\n",
    "    df_copy[col] = le.fit_transform(df_copy[col])\n",
    "    \n",
    "cols = df_copy.columns\n",
    "## normalizing with standard scaler of numerical features\n",
    "df_copy[cols] = ss.fit_transform(df_copy[cols])\n",
    "\n",
    "\n",
    "# correlation map for all the features\n",
    "df_corr = df_copy.drop(columns = ['id']).corr()\n",
    "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "fig.patch.set_facecolor('#f6f5f5')\n",
    "ax.set_facecolor('#f6f5f5')\n",
    "\n",
    "mask = mask[1:, :-1]\n",
    "corr = df_corr.iloc[1:,:-1].copy()\n",
    "\n",
    "\n",
    "colors = ['#f6f5f5','#512b58','#fe346e']\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\",cmap = colormap,\n",
    "           vmin=-0.15, vmax=0.5, cbar_kws={\"shrink\": .5, }, ax = ax, cbar = False,\n",
    "           linewidth = 1,linecolor = '#f6f5f5', square = True,annot_kws = {'font':'serif', 'size':10, 'color':'black'} )\n",
    "# yticks\n",
    "ax.tick_params(axis = 'y', rotation=0)\n",
    "xticks = ['Gender', 'Age','Hyper tension', 'Heart Disease', 'Marriage', 'Work', 'Residence', 'Glucose Level', 'BMI', 'Smoking Status','Stroke','BMI Cat','Age Cat']\n",
    "yticks = ['Gender', 'Age','Hyper tension', 'Heart Disease', 'Marriage', 'Work', 'Residence', 'Glucose Level', 'BMI', 'Smoking Status','Stroke','BMI Cat','Age Cat']\n",
    "ax.set_xticklabels(xticks, {'font':'serif', 'size':10, 'weight':'bold'},rotation = 90, alpha = 0.9)\n",
    "ax.set_yticklabels(yticks, {'font':'serif', 'size':10, 'weight':'bold'}, rotation = 0, alpha = 0.9)\n",
    "ax.text(-3.5,-1.1, 'Correlation Map of Features - How closly each of the features correlated?',{'font':'serif', 'size': 16, 'weight':'bold'}, alpha = 0.9)\n",
    "ax.text(-3.5,-0.65, 'A Glipse on feature correlation for processed feature data.',{'font':'serif', 'size': 12, 'weight':'normal'}, alpha = 0.8)\n",
    "\n",
    "ax.text(9,5, 'Highly correlated positive correlations \\nare exist for Age and Marriage, while \\nwork and other are correlated negatively \\nin highest order.',{'font':'serif', 'size': 9, 'weight':'bold'},alpha = 0.7)\n",
    "ax.text(9,3.7, 'Insight:',{'font':'serif', 'size': 12, 'weight':'bold'},alpha = 0.7)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e24ed-cfe6-4e5d-8d60-3819f70d4eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f4acf-3c9e-4665-8a68-d33c32cdeef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical values\n",
    "\n",
    "df['gender'] = df['gender'].replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\n",
    "df['Residence_type'] = df['Residence_type'].replace({'Rural':0,'Urban':1}).astype(np.uint8)\n",
    "df['work_type'] = df['work_type'].replace({'Private':0,'Self-employed':1,'Govt_job':2,'children':-1,'Never_worked':-2}).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec799141-0aaf-45d9-9db8-480a1b1badc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05655829-4770-4d8a-8c8b-1f8db231d8c2",
   "metadata": {},
   "source": [
    "### Resampling for dataset balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa2ab0-a515-4d10-bb21-0a5caae57809",
   "metadata": {},
   "source": [
    "You can implement SMOTE (Synthetic Minority Over-sampling Technique) to balance your dataset using Python. You'll typically use a library like imbalanced-learn, which provides easy-to-use functions for resampling techniques, including SMOTE. Here's an example of how to use SMOTE in Python:\n",
    "\n",
    "python\n",
    "Copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322c216-4be4-4830-92e2-8f66cd668d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic imbalanced dataset (replace this with your dataset)\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)  # You can adjust 'sampling_strategy' as needed\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "from collections import Counter\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_resampled))\n",
    "\n",
    "# Now, you can train your machine learning model on the resampled data\n",
    "# e.g., using a classifier from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate your model on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Model Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e2169-25d8-4d62-87d6-75cdc9791c23",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "We first generate a synthetic imbalanced dataset using make_classification. Replace this with your actual dataset and labels.\n",
    "\n",
    "We split the dataset into training and testing sets using train_test_split.\n",
    "\n",
    "We apply SMOTE using SMOTE from the imbalanced-learn library. You can adjust the sampling_strategy parameter to control the level of oversampling. \"auto\" means it will balance the classes to be approximately equal.\n",
    "\n",
    "After applying SMOTE, we check the class distribution to confirm that it's balanced.\n",
    "\n",
    "We train a RandomForestClassifier on the resampled data.\n",
    "\n",
    "Finally, we evaluate the model's accuracy on the test set.\n",
    "\n",
    "Make sure to install the imbalanced-learn library if you haven't already using pip install -U imbalanced-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08118e-9a20-4756-b913-621c47de0503",
   "metadata": {},
   "source": [
    "## Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe05cd-6764-499e-a99f-2e1594ea2397",
   "metadata": {},
   "source": [
    "You can implement Random Oversampling to balance your dataset in Python using the imbalanced-learn library. Here's an example of how to do it:\n",
    "\n",
    "python\n",
    "Copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982518c2-890c-4cac-ac39-8652c7d18c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic imbalanced dataset (replace this with your dataset)\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply Random Oversampling to balance the dataset\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)  # You can adjust 'sampling_strategy' as needed\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after Random Oversampling\n",
    "from collections import Counter\n",
    "print(\"Class distribution after Random Oversampling:\", Counter(y_resampled))\n",
    "\n",
    "# Now, you can train your machine learning model on the resampled data\n",
    "# e.g., using a classifier from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate your model on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Model Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cae762-52cd-40b3-9d4c-b7a89650ff18",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "We generate a synthetic imbalanced dataset using make_classification. You should replace this with your actual dataset and labels.\n",
    "\n",
    "We split the dataset into training and testing sets using train_test_split.\n",
    "\n",
    "We apply Random Oversampling using RandomOverSampler from the imbalanced-learn library. You can adjust the sampling_strategy parameter to control the level of oversampling. \"auto\" means it will balance the classes to be approximately equal.\n",
    "\n",
    "After applying Random Oversampling, we check the class distribution to confirm that it's balanced.\n",
    "\n",
    "We train a RandomForestClassifier on the resampled data.\n",
    "\n",
    "Finally, we evaluate the model's accuracy on the test set.\n",
    "\n",
    "Make sure to install the imbalanced-learn library if you haven't already using pip install -U imbalanced-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285e3d1-af5b-41d0-92e5-36b7df1c6842",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450326d-d507-4004-98d9-37529c239a51",
   "metadata": {},
   "source": [
    "You can implement random undersampling to reduce the number of instances in the majority class and balance it with the minority class in Python. Here's an example of how to do it:\n",
    "\n",
    "python\n",
    "Copy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1334b62-e760-4e84-b8ab-83d255160216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a synthetic imbalanced dataset (replace this with your dataset)\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply Random Undersampling to balance the dataset\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)  # You can adjust 'sampling_strategy' as needed\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after Random Undersampling\n",
    "from collections import Counter\n",
    "print(\"Class distribution after Random Undersampling:\", Counter(y_resampled))\n",
    "\n",
    "# Now, you can train your machine learning model on the resampled data\n",
    "# e.g., using a classifier from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate your model on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Model Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893685c-9d15-46ff-a91a-f2b5422abfcc",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "We generate a synthetic imbalanced dataset using make_classification. You should replace this with your actual dataset and labels.\n",
    "\n",
    "We split the dataset into training and testing sets using train_test_split.\n",
    "\n",
    "We apply Random Undersampling using RandomUnderSampler from the imbalanced-learn library. You can adjust the sampling_strategy parameter to control the level of undersampling. \"auto\" means it will balance the classes to be approximately equal.\n",
    "\n",
    "After applying Random Undersampling, we check the class distribution to confirm that it's balanced.\n",
    "\n",
    "We train a RandomForestClassifier on the resampled data.\n",
    "\n",
    "Finally, we evaluate the model's accuracy on the test set.\n",
    "\n",
    "Make sure to install the imbalanced-learn library if you haven't already using pip install -U imbalanced-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b8a17-d1bb-4cb8-b0ed-8ef7df46ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(classifier,x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    classifier.fit(x_train,y_train)\n",
    "    prediction = classifier.predict(x_test)\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10,n_repeats = 3,random_state = 1)\n",
    "    print(\"Cross Validation Score : \",'{0:.2%}'.format(cross_val_score(classifier,x_train,y_train,cv = cv,scoring = 'roc_auc').mean()))\n",
    "    print(\"ROC_AUC Score : \",'{0:.2%}'.format(roc_auc_score(y_test,prediction)))\n",
    "    plot_roc_curve(classifier, x_test,y_test)\n",
    "    plt.title('ROC_AUC_Plot')\n",
    "    plt.show()\n",
    "\n",
    "def model_evaluation(classifier,x_test,y_test):\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test,classifier.predict(x_test))\n",
    "    names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    counts = [value for value in cm.flatten()]\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(names,counts,percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm,annot = labels,cmap = colors,fmt ='')\n",
    "    \n",
    "    # Classification Report\n",
    "    print(classification_report(y_test,classifier.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
